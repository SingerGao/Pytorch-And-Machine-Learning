# 迁移学习

　　实际应用中，很少人会从头开始训练一个卷积神经网络，因为这需要大量的数据样本以及需要长时间的训练。更多情况下是先在一个大的数据集(比如ImageNet)上预训练一个卷积网络，然后以以下两种方式使用预训练好的模型：

- **将预训练的网络作为特征提取器**

  在ImageNet数据集上预训练卷积神经网络，保留前面的卷积、池化层等(可以看成是特征提取器)，移除最后基层的全连接层(可以看成是分类器)。固定住特征提取器，在新的数据集上训练新的分类器(新的全连接层)。

- **微调预训练网络(fine-tuning)**

  这种方式不仅训练最后的分类器，而且需要微调前面的特征提取器。可以微调全部的卷积层，也可以只微调后面的卷积层，因为一般前面的卷积层负责提取一些通用的特征(比如边缘、颜色斑点等特征)，而后续的卷积层提取的特征更针对训练集中的数据。

**问题：如何挑选迁移学习的方式？**

| 　     　　     | very similar dataset |very different dataset |
| -------------- | -------------------- | --------------------- |
|very little data| ConvNet as fixed feature extractor, retrain classifier. | You are in trouble. |
| a lot of data  | Finetune a few layers. | Finetune a large number of layers. |

